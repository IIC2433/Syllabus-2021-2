{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da2f402",
   "metadata": {},
   "source": [
    "# Tarea 4\n",
    "\n",
    "Cuentas con un set de datos de imágenes en blanco y negro (de 28x28 pixeles) de distintas prendas de vestir (son 10 tipos de prendas en total, mira [aca](https://github.com/zalandoresearch/fashion-mnist)). En esta tarea vas a resolver el problema de crear nuevas imágenes prendas de vestir. Especificamente, la tarea que se te ha encomendado es:\n",
    "\n",
    "> Elige dos tipos de los 10 tipos de prendas\n",
    ">>Para cada uno de esos dos tipos, escribe una función que retorne uno de esos dos tipos, y retorne una nueva imagen de ese tipo, obtenida al azar, que no esté ya en el dataset\n",
    "\n",
    "La solución a trabajar para escribir esta funcion consta de las siguientes partes\n",
    "\n",
    "### Parte 1: datos, reducción de dimensionalidad\n",
    "\n",
    "- Prueba dos formas de reducir a 6 dimensiones: PCA y autoencoders. \n",
    "- Busca 3 imágenes en el dataset. Para esas tres imágenes, compara visualmente lo que ocurre al (1) graficar la imagen original (hay código para eso más abajo) y (2) tomar el vector de la imagen, codificarlo, decodificarlo y volver a graficar (para pca y autoencoder, recuerda estandarizar y luego des-estandarizar, como hicimos en el notebook de compresión de la semana 9). \n",
    "- Sigue afinando tu método de reducción hasta que entregue imágenes que al codificar/decodificar, la imagen nueva resultante todavía guarde alguna semejanza con la realidad. \n",
    "- Una vez que estés satisfecho, transforma todo el dataset con tu método de reducción. Al dataset resultante (ahora con 6 dimensiones) le llamaremos **Xreducido**\n",
    "\n",
    "### Parte 2: clustering y sampling \n",
    "\n",
    "- Ejecuta un algoritmo de clustering GMM sobre **Xreducido**, con 10 clústeres. Averigua como obtener las medias y las covarianzas de los 10 clústeres resultantes. \n",
    "- Usa *np.random.multivariate_normal(mean_vector,covariance_matrix)*, que se usa para obtener un elemento de la normal multivariada con su vector de media *mean_vector* y matriz de covarianzas *covariance_matrix*, para obtener un sample de cada una de las 10 gaussianas que entrenó tu GMM\n",
    "\n",
    "### Parte 3: análisis  \n",
    "\n",
    "- Cada sample puede ser graficado como imagen: hay que pasarlo por el decodificador (o la transformada inversa en el caso de PCA). \n",
    "- Analiza visualmente dos samples de cada clase\n",
    "- Analiza visualmente la media de cada cluster identificado por GMM\n",
    "- Con las visualizaciones de esta parte, responde: ¿qué clústeres parece entregar consistentemente prendas de un tipo en específico? ¿qué prendas son?\n",
    "- Entrena un clasificador de randomforest con los datos originales. \n",
    "- Samplea y decodifica 50 ejemplos de cada cluster identificado por GMM, y entrégaselos al randomforest. Ahora ve los resultados de las predicciones. Vé si son consistentes en el sentido de que predicen que una buena cantidad de los ejemplos de los dos clústeres que identificaste son de una prenda en particular. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756cc98",
   "metadata": {},
   "source": [
    "### Detalles académicos\n",
    "\n",
    "La entrega de esta tarea es el Viernes 19 de Noviembre, a las 20:00, por cuestionario en SIDING. Se debe subir solo un archivo de jupyter notebook. Te pedimos también por favor nombrar tu archivo con el formato **NumeroAlumno_Apellido_Nombre**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae35d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1444bcb7",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1425a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d27118",
   "metadata": {},
   "source": [
    "Bajamos el dataset, nos quedamos con 10.000 tuplas (esto es opcional, para que todo cargue más rápido, mientras más tuplas se dejen, mejor deberían ser los resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ba51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('Fashion-MNIST', version=1, as_frame=True)\n",
    "mnist.keys()\n",
    "\n",
    "X, y = mnist['data'], mnist['target']\n",
    "X_sample = X[60000:]\n",
    "y_sample = y[60000:]\n",
    "X_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e72f4",
   "metadata": {},
   "source": [
    "### Mostrando una foto\n",
    "Para mostrar las fotos, tenemos que volver a formato de 28x28 píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582c49db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14908/4199082902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#sacar la entidad numero 2000 del dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msome_garment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msome_garment_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msome_garment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_sample' is not defined"
     ]
    }
   ],
   "source": [
    "#sacar la entidad numero 2000 del dataset \n",
    "\n",
    "some_garment = X_sample.iloc[2000]\n",
    "some_garment_image = some_garment.values.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_garment_image, cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442bd5df",
   "metadata": {},
   "source": [
    "# ACA COMIENZA TU TRABAJO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60e0d0",
   "metadata": {},
   "source": [
    "# Parte 1: reducir dimensionalidad\n",
    "¡Recuerda estandarizar los datos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134934a3",
   "metadata": {},
   "source": [
    "Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f66a538",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce08ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87ed7f03",
   "metadata": {},
   "source": [
    "Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a28d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bdb482",
   "metadata": {},
   "source": [
    "Finalmente: ¿Con qué estrategia para reducir dimensionalidad te quedas? Transforma *X_sample* a *X_reducido*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67c5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba35e07",
   "metadata": {},
   "source": [
    "# Parte 2: Sampleo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c5e818",
   "metadata": {},
   "source": [
    "Hacer fit de un modelo GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573145d3",
   "metadata": {},
   "source": [
    "Código para samplear de un cluster en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42405d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91190b4a",
   "metadata": {},
   "source": [
    "# Parte 3: Comparación PCA/Autoencoder en base a samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23715df9",
   "metadata": {},
   "source": [
    "Analiza visualmente dos samples de cada clase (toma dos samples de cada clase, decodifica, des-estandariza y grafica como mostramos en la parte de datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f066f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b3fb65",
   "metadata": {},
   "source": [
    "Analiza visualmente la meda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330855c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56843d3e",
   "metadata": {},
   "source": [
    "¿qué clústeres parece entregar consistentemente prendas de un tipo en específico? ¿qué prendas son?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaa659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53f25a38",
   "metadata": {},
   "source": [
    "Entrena un clasificador de randomforest con los datos originales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad39a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e374a17e",
   "metadata": {},
   "source": [
    "Samplea y decodifica 50 ejemplos de cada cluster identificado por GMM, y entrégaselos al randomforest. Ahora ve los resultados de las predicciones. Vé si son consistentes en el sentido de que predicen que una buena cantidad de los ejemplos de los dos clústeres que identificaste son de una prenda en particular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e8eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
